Hi Replit, so as you see I have webapp which is IndexNow a 3rd party to request to GSC API to index a link. This webapp is same and inspirated by Instant Indexing wordpress plugin by RankMath.

So, as this webapp is on development stage and for personal use only. I need you to focus to enhance and fix some problem in dashboard and panel.

Before you do make the changes, I need you to do a deep dive into the codebase, so you do have better understanding about this webapp, the current stage and feature and the obstacles.

Before we more in-deepth about this project. Please take time to read all information in replit.md because there's a lot important things that you should know.

After that, I want you to fix the error when I open manage jobs page

Before, I ask you about this:
'''No need to restart the app, I want to stop it, question again in database before you made table "indb_indexing_job_logs" with column table like this:
| column_name | data_type                | is_nullable | column_default     |
| ----------- | ------------------------ | ----------- | ------------------ |
| id          | uuid                     | NO          | uuid_generate_v4() |
| job_id      | uuid                     | NO          | null               |
| level       | text                     | NO          | null               |
| message     | text                     | NO          | null               |
| metadata    | jsonb                    | YES         | null               |
| created_at  | timestamp with time zone | YES         | now()              |
'''

Then you answer with:
Great question! The indb_indexing_job_logs table is designed for detailed logging and debugging of job execution processes. Here's what it's supposed to handle:

Purpose of the table:

Job Activity Logging: Track detailed events during job processing (start, progress, completion, errors)
Debug Information: Store step-by-step logs for troubleshooting failed jobs
Audit Trail: Maintain a history of what happened during each job execution
Performance Monitoring: Log timing information and processing details
Column Usage:

job_id: Links each log entry to a specific indexing job
level: Log severity (INFO, WARN, ERROR, DEBUG) for filtering
message: Human-readable description of what happened
metadata: JSON data for structured information (URLs processed, API responses, timing data)
created_at: Timestamp for chronological ordering
Example log entries would be:

level: "INFO", message: "Started processing 50 URLs"
level: "ERROR", message: "Google API quota exceeded", metadata: {"service_account_id": "xxx", "remaining_quota": 0}
level: "DEBUG", message: "Successfully indexed URL", metadata: {"url": "example.com", "response_time": "150ms"}
This table provides granular visibility into job execution, making it easier to diagnose issues, monitor performance, and understand exactly what happened during each indexing operation. It's particularly valuable for debugging complex job failures or tracking processing statistics.

But, the actual situation is, the table is doesn't record any data even though I already run some jobs and make a bit bunch of url submission.

So, I need you to fix it based on what the tables supposed to record data.

Current example data:
INSERT INTO "public"."indb_indexing_job_logs" ("id", "job_id", "level", "message", "metadata", "created_at") VALUES ('0467e941-7bd1-449f-ba98-0a7d5dbc6b6c', '16f86f9e-1eda-4ad5-a143-967fc6b1b1d6', 'info', 'Job started: #Job-4', '{"job_name": "#Job-4", "event_type": "job_started", "started_at": "2025-07-23T12:28:02.443Z", "total_urls": 1}', '2025-07-23 12:28:02.443+00');